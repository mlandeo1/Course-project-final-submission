{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mental Health Sentiment Analyzer\n",
    "\n",
    "**Student:** Marco Landeo (mlandeo@stevens.edu)\n",
    "\n",
    "This notebook performs sentiment analysis on text data to identify mental health-related sentiment trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required modules\n",
    "from text_dataset import TextDataset\n",
    "from sentiment_analyzer import SentimentAnalyzer\n",
    "from utils import calculate_accuracy, generate_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "print(\"All modules imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: TextDataset(file_path='sample_data.csv', num_texts=10)\n",
      "Number of texts: 10\n"
     ]
    }
   ],
   "source": [
    "# Load dataset with exception handling\n",
    "try:\n",
    "    dataset = TextDataset('sample_data.csv')\n",
    "    print(f\"Dataset loaded: {dataset}\")\n",
    "    print(f\"Number of texts: {len(dataset.raw_texts)}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    print(\"Please ensure sample_data.csv exists in the current directory.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed 10 texts\n",
      "Sample cleaned text: i feel great today and everything is wonderful\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text data\n",
    "dataset.preprocess()\n",
    "print(f\"Preprocessed {len(dataset.cleaned_texts)} texts\")\n",
    "print(f\"Sample cleaned text: {dataset.cleaned_texts[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Perform Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzer created: SentimentAnalyzer(dataset=TextDataset(file_path='sample_data.csv', num_texts=10), analyzed_texts=0)\n",
      "Analysis complete! Analyzed 10 texts\n"
     ]
    }
   ],
   "source": [
    "# Create SentimentAnalyzer instance\n",
    "analyzer = SentimentAnalyzer(dataset)\n",
    "print(f\"Analyzer created: {analyzer}\")\n",
    "\n",
    "# Analyze all texts\n",
    "analyzer.analyze_all()\n",
    "print(f\"Analysis complete! Analyzed {len(analyzer.results)} texts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Distribution:\n",
      "  positive: 4\n",
      "  neutral: 3\n",
      "  negative: 3\n"
     ]
    }
   ],
   "source": [
    "# Display sentiment counts\n",
    "print(\"Sentiment Distribution:\")\n",
    "for sentiment, count in analyzer.sentiment_counts.items():\n",
    "    print(f\"  {sentiment}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualize Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization saved to sentiment_distribution.png\n",
      "Visualization saved!\n"
     ]
    }
   ],
   "source": [
    "# Create visualizations\n",
    "analyzer.visualize_results('sentiment_distribution.png')\n",
    "print(\"Visualization saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report saved to sentiment_report.json\n",
      "Report generated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Generate and save report\n",
    "try:\n",
    "    generate_report(analyzer, 'sentiment_report.json')\n",
    "    print(\"Report generated successfully!\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error generating report: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Calculate Accuracy (if ground truth available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Example accuracy calculation\n",
    "# Note: This is a demonstration. In practice, you would load actual ground truth labels\n",
    "# from your dataset. Here we create sample actual labels for demonstration purposes.\n",
    "predictions = [result['sentiment'] for result in analyzer.results]\n",
    "\n",
    "# Sample actual labels for demonstration (in real use, load from dataset)\n",
    "# This creates a mix of correct and incorrect predictions to show the function works\n",
    "actual = ['positive', 'neutral', 'negative', 'positive', 'neutral', \n",
    "          'negative', 'positive', 'negative', 'positive', 'negative']\n",
    "\n",
    "try:\n",
    "    accuracy = calculate_accuracy(predictions, actual)\n",
    "    print(f\"Accuracy: {accuracy:.2%}\")\n",
    "    print(\"Note: This uses sample labels for demonstration. Use real ground truth in practice.\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error calculating accuracy: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Interactive Testing (While Loop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive Sentiment Analysis\n",
      "Type 'quit' to exit\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a sentence to analyze (or 'quit' to exit):  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting interactive mode.\n"
     ]
    }
   ],
   "source": [
    "# Interactive sentiment analysis (while loop example)\n",
    "if 'analyzer' not in globals():\n",
    "    print(\"Error: 'analyzer' object not found. Please run Step 2 first.\")\n",
    "else:\n",
    "    print(\"Interactive Sentiment Analysis\")\n",
    "    print(\"Type 'quit' to exit\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    user_input = \"\"\n",
    "    while user_input.lower() != 'quit':\n",
    "        user_input = input(\"Enter a sentence to analyze (or 'quit' to exit): \")\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            break\n",
    "        \n",
    "        if user_input.strip():\n",
    "            sentiment = analyzer.analyze_sentiment(user_input)\n",
    "            print(f\"Sentiment: {sentiment}\")\n",
    "            print(\"-\" * 40)\n",
    "        else:\n",
    "            print(\"Please enter a valid sentence.\")\n",
    "            print(\"-\" * 40)\n",
    "    \n",
    "    print(\"Exiting interactive mode.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Demonstrate Advanced Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using generator to process batches:\n",
      "Batch 1: 3 texts\n",
      "Batch 2: 3 texts\n",
      "Batch 3: 3 texts\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate generator function\n",
    "print(\"Using generator to process batches:\")\n",
    "batch_count = 0\n",
    "for batch in dataset.batch_generator(batch_size=3):\n",
    "    batch_count += 1\n",
    "    print(f\"Batch {batch_count}: {len(batch)} texts\")\n",
    "    if batch_count >= 3:  # Limit output\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstrating operator overloading:\n",
      "Original dataset: 10 texts\n",
      "Merged dataset: 11 texts\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate operator overloading (__add__)\n",
    "print(\"Demonstrating operator overloading:\")\n",
    "print(f\"Original dataset: {len(dataset.raw_texts)} texts\")\n",
    "\n",
    "# Create a second small dataset for merging\n",
    "try:\n",
    "    # Create a temporary second dataset\n",
    "    import tempfile\n",
    "    with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:\n",
    "        f.write(\"text\\n\")\n",
    "        f.write(\"Additional text for merging\\n\")\n",
    "        temp_file = f.name\n",
    "    \n",
    "    dataset2 = TextDataset(temp_file)\n",
    "    merged_dataset = dataset + dataset2\n",
    "    print(f\"Merged dataset: {len(merged_dataset.raw_texts)} texts\")\n",
    "    \n",
    "    import os\n",
    "    os.unlink(temp_file)\n",
    "except Exception as e:\n",
    "    print(f\"Error in merging: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most frequent words:\n",
      "  and: 5\n",
      "  about: 4\n",
      "  this: 3\n",
      "  i: 2\n",
      "  feel: 2\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate word frequencies\n",
    "word_freq = dataset.get_word_frequencies()\n",
    "print(\"Top 5 most frequent words:\")\n",
    "sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "for word, freq in sorted_words[:5]:\n",
    "    print(f\"  {word}: {freq}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment categories (immutable tuple): ('positive', 'neutral', 'negative')\n",
      "Type: <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate tuple return type\n",
    "categories = dataset.get_sentiment_categories()\n",
    "print(f\"Sentiment categories: {categories}\")\n",
    "print(f\"Type: {type(categories)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "  total_texts: 10\n",
      "  positive_percentage: 40.00\n",
      "  neutral_percentage: 30.00\n",
      "  negative_percentage: 30.00\n"
     ]
    }
   ],
   "source": [
    "# Display summary statistics\n",
    "stats = analyzer.get_summary_statistics()\n",
    "print(\"Summary Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
